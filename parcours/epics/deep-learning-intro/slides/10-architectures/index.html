<!DOCTYPE html>
<html lang="fr" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Les Grandes Architectures - Deep Learning</title>

    <link rel="stylesheet" href="../../../../../lib/theme.css">
    <link rel="stylesheet" href="../../_shared/deep-learning.css">
    <script src="https://cdn.tailwindcss.com"></script>

    <script type="module">
        import { initSlide } from '../../../../../parcours/_shared/slide-utils.js';
        initSlide();
    </script>
</head>
<body class="antialiased selection:bg-blue-500 selection:text-white">

    <!-- Hero Section -->
    <header class="hero-section relative py-16 overflow-hidden border-b">
        <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 relative z-10">
            <div class="inline-block mb-4 px-3 py-1 rounded-full bg-orange-500/10 border border-orange-500/20 text-orange-400 text-xs font-medium">
                Panorama
            </div>
            <h1 class="text-4xl md:text-5xl font-extrabold dl-text-primary tracking-tight mb-4">
                Les Grandes <span class="bg-gradient-to-r from-orange-400 to-red-500 bg-clip-text text-transparent">Architectures</span>
            </h1>
            <p class="max-w-2xl text-lg dl-text-muted">
                CNN, RNN, Transformers, Diffusion : les familles de r√©seaux qui ont r√©volutionn√© le Deep Learning.
            </p>
        </div>
        <div class="hero-grid absolute inset-0 bg-[size:4rem_4rem] [mask-image:radial-gradient(ellipse_60%_50%_at_50%_0%,#000_70%,transparent_100%)] opacity-30 pointer-events-none"></div>
    </header>

    <main class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-16">

        <p class="dl-text-secondary mb-12">
            Au-del√† du r√©seau dense (fully connected) que nous avons √©tudi√©, il existe des architectures sp√©cialis√©es pour diff√©rents types de donn√©es. Voici les quatre familles majeures.
        </p>

        <!-- CNN -->
        <section id="cnn" class="mb-12">
            <div class="dl-card p-6 rounded-xl border border-blue-500/30">
                <div class="flex items-start gap-4">
                    <div class="text-4xl">üñºÔ∏è</div>
                    <div class="flex-grow">
                        <h2 class="text-2xl font-bold text-blue-400 mb-2">CNN - R√©seaux Convolutifs</h2>
                        <p class="text-sm dl-text-muted mb-4">Convolutional Neural Networks</p>

                        <div class="concept-box mb-4">
                            <h4 class="font-bold text-blue-300 mb-2">Principe</h4>
                            <p class="text-sm dl-text-secondary">
                                Les <dfn>convolutions</dfn> d√©tectent des patterns locaux en scannant l'image avec des filtres. Chaque filtre apprend √† reconna√Ætre une caract√©ristique (lignes, courbes, textures) puis, couche apr√®s couche, des formes de plus en plus complexes.
                            </p>
                        </div>

                        <div class="analogy-box mb-4">
                            <p class="text-sm dl-text-secondary">
                                <strong class="text-green-400">Analogie :</strong> Scanner une photo avec une loupe qu'on d√©place partout. Chaque position analyse un petit motif, et la combinaison cr√©e la compr√©hension globale.
                            </p>
                        </div>

                        <div class="grid md:grid-cols-2 gap-4 text-xs mb-4">
                            <div>
                                <h5 class="font-bold text-blue-300 mb-2">Cas d'usage</h5>
                                <ul class="dl-text-muted space-y-1">
                                    <li>‚Ä¢ Classification d'images</li>
                                    <li>‚Ä¢ D√©tection d'objets</li>
                                    <li>‚Ä¢ Reconnaissance faciale</li>
                                    <li>‚Ä¢ Imagerie m√©dicale</li>
                                </ul>
                            </div>
                            <div>
                                <h5 class="font-bold text-blue-300 mb-2">√âvolutions notables</h5>
                                <ul class="dl-text-muted space-y-1">
                                    <li>‚Ä¢ <strong>LeNet</strong> (1998) : chiffres manuscrits</li>
                                    <li>‚Ä¢ <strong>AlexNet</strong> (2012) : r√©volution ImageNet</li>
                                    <li>‚Ä¢ <strong>ResNet</strong> (2015) : 152 couches, connexions r√©siduelles</li>
                                </ul>
                            </div>
                        </div>

                        <div class="text-xs bg-blue-500/10 p-3 rounded border border-blue-500/20">
                            <strong class="text-blue-300">Chercheurs cl√©s :</strong>
                            <strong>Yann LeCun</strong> (Bell Labs ‚Üí Meta AI) invente les CNN avec LeNet pour reconna√Ætre les chiffres manuscrits.
                            <strong>Alex Krizhevsky</strong>, <strong>Ilya Sutskever</strong> et <strong>Geoffrey Hinton</strong> (U. Toronto) d√©clenchent la r√©volution Deep Learning avec AlexNet, r√©duisant l'erreur ImageNet de 26% √† 15%.
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- RNN/LSTM -->
        <section id="rnn" class="mb-12">
            <div class="dl-card p-6 rounded-xl border border-green-500/30">
                <div class="flex items-start gap-4">
                    <div class="text-4xl">üìú</div>
                    <div class="flex-grow">
                        <h2 class="text-2xl font-bold text-green-400 mb-2">RNN / LSTM - R√©seaux R√©currents</h2>
                        <p class="text-sm dl-text-muted mb-4">Recurrent Neural Networks / Long Short-Term Memory</p>

                        <div class="concept-box mb-4">
                            <h4 class="font-bold text-green-300 mb-2">Principe</h4>
                            <p class="text-sm dl-text-secondary">
                                Les RNN traitent les s√©quences en maintenant une "m√©moire cach√©e" des √©tapes pr√©c√©dentes. Les <dfn>LSTM</dfn> am√©liorent cette m√©moire gr√¢ce √† des "portes" qui contr√¥lent quoi retenir ou oublier.
                            </p>
                        </div>

                        <div class="analogy-box mb-4">
                            <p class="text-sm dl-text-secondary">
                                <strong class="text-green-400">Analogie :</strong> Lire un livre en se souvenant des chapitres pr√©c√©dents. Chaque nouveau chapitre a du sens gr√¢ce √† ce qu'on a d√©j√† lu.
                            </p>
                        </div>

                        <div class="grid md:grid-cols-2 gap-4 text-xs mb-4">
                            <div>
                                <h5 class="font-bold text-green-300 mb-2">Cas d'usage</h5>
                                <ul class="dl-text-muted space-y-1">
                                    <li>‚Ä¢ Traduction automatique</li>
                                    <li>‚Ä¢ Pr√©diction de texte</li>
                                    <li>‚Ä¢ S√©ries temporelles (finance, m√©t√©o)</li>
                                    <li>‚Ä¢ Reconnaissance vocale</li>
                                </ul>
                            </div>
                            <div>
                                <h5 class="font-bold text-green-300 mb-2">Limite majeure</h5>
                                <p class="dl-text-muted">
                                    M√™me les LSTM peinent avec les tr√®s longues d√©pendances (>500 tokens). La m√©moire "s'estompe" progressivement.
                                </p>
                            </div>
                        </div>

                        <div class="text-xs bg-green-500/10 p-3 rounded border border-green-500/20">
                            <strong class="text-green-300">Chercheurs cl√©s :</strong>
                            Les RNN classiques souffraient du <em>vanishing gradient</em> (gradient qui dispara√Æt).
                            <strong>Sepp Hochreiter</strong> et <strong>J√ºrgen Schmidhuber</strong> (TU Munich, 1997) inventent les LSTM avec leurs "portes" (forget, input, output) pour r√©soudre ce probl√®me.
                            Les GRU (2014) de <strong>Cho et al.</strong> simplifient le concept.
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Transformers -->
        <section id="transformers" class="mb-12">
            <div class="dl-card p-6 rounded-xl border border-purple-500/30 bg-purple-500/5">
                <div class="flex items-start gap-4">
                    <div class="text-4xl">ü§ñ</div>
                    <div class="flex-grow">
                        <h2 class="text-2xl font-bold text-purple-400 mb-2">Transformers</h2>
                        <p class="text-sm dl-text-muted mb-4">L'architecture dominante depuis 2017</p>

                        <div class="concept-box mb-4">
                            <h4 class="font-bold text-purple-300 mb-2">Principe</h4>
                            <p class="text-sm dl-text-secondary">
                                Le m√©canisme d'<dfn>attention</dfn> permet de regarder tous les tokens de la s√©quence en parall√®le et de comprendre leurs relations mutuelles. Plus de traitement s√©quentiel mot par mot.
                            </p>
                        </div>

                        <div class="analogy-box mb-4">
                            <p class="text-sm dl-text-secondary">
                                <strong class="text-green-400">Analogie :</strong> Lire toute la page d'un coup plut√¥t que mot par mot. On voit les connexions entre le d√©but et la fin sans "oublier" en chemin.
                            </p>
                        </div>

                        <div class="grid md:grid-cols-2 gap-4 text-xs mb-4">
                            <div>
                                <h5 class="font-bold text-purple-300 mb-2">Cas d'usage</h5>
                                <ul class="dl-text-muted space-y-1">
                                    <li>‚Ä¢ NLP : traduction, r√©sum√©, g√©n√©ration</li>
                                    <li>‚Ä¢ LLMs : ChatGPT, Claude, Gemini</li>
                                    <li>‚Ä¢ Vision : ViT (Vision Transformer)</li>
                                    <li>‚Ä¢ Multimodal : CLIP, GPT-4 Vision</li>
                                </ul>
                            </div>
                            <div>
                                <h5 class="font-bold text-purple-300 mb-2">√âvolutions notables</h5>
                                <ul class="dl-text-muted space-y-1">
                                    <li>‚Ä¢ <strong>BERT</strong> (2018) : compr√©hension bidirectionnelle</li>
                                    <li>‚Ä¢ <strong>GPT</strong> : g√©n√©ration autor√©gressive</li>
                                    <li>‚Ä¢ <strong>ViT</strong> : Transformers pour la vision</li>
                                </ul>
                            </div>
                        </div>

                        <div class="text-xs bg-purple-500/10 p-3 rounded border border-purple-500/20 mb-3">
                            <strong class="text-purple-300">Papier fondateur :</strong>
                            <em>"Attention Is All You Need"</em> (2017) par <strong>Vaswani et al.</strong> chez Google Brain.
                            L'√©quipe : Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, ≈Åukasz Kaiser et Illia Polosukhin ‚Äî beaucoup ont depuis fond√© des startups (Cohere, Character.ai, Adept...).
                        </div>

                        <div class="text-xs bg-purple-500/10 p-3 rounded border border-purple-500/20">
                            <strong class="text-purple-300">‚ö†Ô∏è Limite :</strong> Complexit√© <strong>O(n¬≤)</strong> avec la longueur de s√©quence ‚Äî c'est ce qui motive les alternatives √©mergentes.
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Mod√®les de Diffusion -->
        <section id="diffusion" class="mb-12">
            <div class="dl-card p-6 rounded-xl border border-pink-500/30">
                <div class="flex items-start gap-4">
                    <div class="text-4xl">üé®</div>
                    <div class="flex-grow">
                        <h2 class="text-2xl font-bold text-pink-400 mb-2">Mod√®les de Diffusion</h2>
                        <p class="text-sm dl-text-muted mb-4">Diffusion Models - La r√©volution de la g√©n√©ration d'images</p>

                        <div class="concept-box mb-4">
                            <h4 class="font-bold text-pink-300 mb-2">Principe</h4>
                            <p class="text-sm dl-text-secondary">
                                Apprendre √† <dfn>d√©bruiter</dfn> progressivement : on entra√Æne le mod√®le √† enlever le bruit d'une image √©tape par √©tape. Pour g√©n√©rer, on part de bruit pur et on applique le d√©bruitage (~100 √©tapes).
                            </p>
                        </div>

                        <div class="analogy-box mb-4">
                            <p class="text-sm dl-text-secondary">
                                <strong class="text-green-400">Analogie :</strong> Sculpter une statue √† partir du chaos. On commence avec du bruit al√©atoire, puis on affine progressivement jusqu'√† obtenir une image coh√©rente.
                            </p>
                        </div>

                        <div class="grid md:grid-cols-2 gap-4 text-xs mb-4">
                            <div>
                                <h5 class="font-bold text-pink-300 mb-2">Cas d'usage</h5>
                                <ul class="dl-text-muted space-y-1">
                                    <li>‚Ä¢ G√©n√©ration d'images (DALL-E, Midjourney)</li>
                                    <li>‚Ä¢ Stable Diffusion (open source)</li>
                                    <li>‚Ä¢ √âdition et inpainting d'images</li>
                                    <li>‚Ä¢ Super-r√©solution</li>
                                </ul>
                            </div>
                            <div>
                                <h5 class="font-bold text-pink-300 mb-2">Optimisation cl√©</h5>
                                <p class="dl-text-muted">
                                    <strong>Diffusion latente</strong> : travailler sur une version compress√©e (64x64) plut√¥t que l'image compl√®te (512x512) pour r√©duire drastiquement le temps de calcul.
                                </p>
                            </div>
                        </div>

                        <div class="text-xs bg-pink-500/10 p-3 rounded border border-pink-500/20">
                            <strong class="text-pink-300">Chercheurs cl√©s :</strong>
                            <strong>Jonathan Ho</strong>, Ajay Jain et <strong>Pieter Abbeel</strong> (UC Berkeley, 2020) publient <em>"Denoising Diffusion Probabilistic Models"</em> (DDPM).
                            <strong>Robin Rombach</strong> et al. (2022) inventent la diffusion latente (Stable Diffusion), rendant la technique accessible √† tous.
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Architectures √©mergentes -->
        <section id="emergentes" class="mb-12">
            <div class="flex items-center gap-3 mb-6">
                <span class="text-3xl">üöÄ</span>
                <h2 class="text-3xl font-bold dl-text-primary">Alternatives √©mergentes</h2>
            </div>

            <p class="dl-text-secondary mb-6">
                La complexit√© O(n¬≤) des Transformers pousse les chercheurs √† explorer des alternatives. Voici les plus prometteuses de 2023-2025.
            </p>

            <div class="grid md:grid-cols-2 gap-4 mb-6">
                <!-- Mamba / SSM -->
                <div class="dl-card p-4 rounded-xl border border-teal-500/30">
                    <div class="flex items-start gap-3">
                        <span class="text-2xl">üêç</span>
                        <div>
                            <h4 class="font-bold text-teal-400 mb-1">Mamba / SSM</h4>
                            <p class="text-xs dl-text-muted mb-2">State Space Models s√©lectifs</p>
                            <p class="text-sm dl-text-secondary mb-2">
                                Des mod√®les inspir√©s de la th√©orie du contr√¥le, avec une <strong>complexit√© lin√©aire O(n)</strong> et une inf√©rence O(1) par token.
                            </p>
                            <div class="text-xs dl-text-muted space-y-1">
                                <p><strong class="text-teal-300">Chercheurs :</strong> <strong>Albert Gu</strong> et <strong>Tri Dao</strong> (CMU/Princeton, 2023)</p>
                                <p><strong class="text-teal-300">Innovation :</strong> SSMs "s√©lectifs" ‚Äî le mod√®le choisit quoi retenir</p>
                                <p><strong class="text-teal-300">Perf :</strong> Throughput 5√ó sup√©rieur aux Transformers, jusqu'√† 1M tokens</p>
                                <p><strong class="text-teal-300">Adoption :</strong> Codestral Mamba (Mistral), Jamba (AI21), IBM Granite 4.0</p>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- RWKV -->
                <div class="dl-card p-4 rounded-xl border border-amber-500/30">
                    <div class="flex items-start gap-3">
                        <span class="text-2xl">ü¶ú</span>
                        <div>
                            <h4 class="font-bold text-amber-400 mb-1">RWKV</h4>
                            <p class="text-xs dl-text-muted mb-2">Receptance Weighted Key Value</p>
                            <p class="text-sm dl-text-secondary mb-2">
                                Un RNN qui <strong>scale comme un Transformer</strong> ‚Äî entra√Ænement parall√®le, inf√©rence O(1).
                            </p>
                            <div class="text-xs dl-text-muted space-y-1">
                                <p><strong class="text-amber-300">Cr√©ateur :</strong> <strong>Bo Peng</strong> (BlinkDL), 2021-2023</p>
                                <p><strong class="text-amber-300">Innovation :</strong> 100% sans attention, contexte illimit√©</p>
                                <p><strong class="text-amber-300">Organisation :</strong> Linux Foundation depuis 2023</p>
                                <p><strong class="text-amber-300">Version :</strong> RWKV-7 "Goose" (2025)</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="grid md:grid-cols-2 gap-4 mb-6">
                <!-- KAN -->
                <div class="dl-card p-4 rounded-xl border border-rose-500/30">
                    <div class="flex items-start gap-3">
                        <span class="text-2xl">üìê</span>
                        <div>
                            <h4 class="font-bold text-rose-400 mb-1">KAN</h4>
                            <p class="text-xs dl-text-muted mb-2">Kolmogorov-Arnold Networks</p>
                            <p class="text-sm dl-text-secondary mb-2">
                                Remplace les MLP classiques par des fonctions sur les <strong>ar√™tes</strong> (splines) au lieu des n≈ìuds ‚Äî hautement interpr√©table.
                            </p>
                            <div class="text-xs dl-text-muted space-y-1">
                                <p><strong class="text-rose-300">Chercheurs :</strong> <strong>Ziming Liu</strong> et <strong>Max Tegmark</strong> (MIT, 2024)</p>
                                <p><strong class="text-rose-300">Base :</strong> Th√©or√®me de Kolmogorov-Arnold (1957)</p>
                                <p><strong class="text-rose-300">Atout :</strong> Visualisation des fonctions apprises, d√©couverte de lois physiques</p>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Liquid Foundation Models -->
                <div class="dl-card p-4 rounded-xl border border-indigo-500/30">
                    <div class="flex items-start gap-3">
                        <span class="text-2xl">üíß</span>
                        <div>
                            <h4 class="font-bold text-indigo-400 mb-1">LFM (Liquid AI)</h4>
                            <p class="text-xs dl-text-muted mb-2">Liquid Foundation Models</p>
                            <p class="text-sm dl-text-secondary mb-2">
                                Foundation models bas√©s sur les <strong>neurones liquides</strong> ‚Äî compacts, efficaces, interpr√©tables.
                            </p>
                            <div class="text-xs dl-text-muted space-y-1">
                                <p><strong class="text-indigo-300">Fondateurs :</strong> <strong>Ramin Hasani</strong>, <strong>Daniela Rus</strong> (MIT CSAIL)</p>
                                <p><strong class="text-indigo-300">Financement :</strong> $250M lev√©s, valorisation $2.35B (2024)</p>
                                <p><strong class="text-indigo-300">LFM2 :</strong> 2√ó plus rapide que Qwen3 sur CPU (2025)</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="dl-card bg-gradient-to-r from-teal-500/10 to-purple-500/10 border-l-4 border-teal-500 p-4">
                <p class="text-sm dl-text-secondary">
                    <strong class="text-teal-400">Tendance 2024-2025 :</strong> Les mod√®les <strong>hybrides</strong> combinent le meilleur des deux mondes ‚Äî couches d'attention pour les d√©pendances complexes, et SSM/convolutions pour l'efficacit√©. Exemples : Jamba (Mamba + attention), StripedHyena, IBM Granite 4.0.
                </p>
            </div>
        </section>

        <!-- Tableau r√©capitulatif -->
        <section id="recap">
            <div class="flex items-center gap-3 mb-6">
                <span class="text-3xl">üìä</span>
                <h2 class="text-3xl font-bold dl-text-primary">R√©capitulatif</h2>
            </div>

            <div class="overflow-x-auto mb-8">
                <table class="w-full text-sm">
                    <thead>
                        <tr class="border-b border-blue-500/30">
                            <th class="text-left py-3 px-2 font-bold dl-text-primary">Architecture</th>
                            <th class="text-left py-3 px-2 font-bold dl-text-primary">Ann√©e</th>
                            <th class="text-left py-3 px-2 font-bold dl-text-primary">Sp√©cialit√©</th>
                            <th class="text-left py-3 px-2 font-bold dl-text-primary">Complexit√©</th>
                        </tr>
                    </thead>
                    <tbody class="divide-y divide-blue-500/20">
                        <tr>
                            <td class="py-3 px-2 text-blue-400 font-bold">CNN</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">1998</td>
                            <td class="py-3 px-2 dl-text-secondary">Images, vision</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">O(k¬≤¬∑n)</td>
                        </tr>
                        <tr>
                            <td class="py-3 px-2 text-green-400 font-bold">RNN/LSTM</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">1997</td>
                            <td class="py-3 px-2 dl-text-secondary">S√©quences</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">O(n) s√©quentiel</td>
                        </tr>
                        <tr>
                            <td class="py-3 px-2 text-purple-400 font-bold">Transformer</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">2017</td>
                            <td class="py-3 px-2 dl-text-secondary">Tout (LLMs, vision...)</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">O(n¬≤) ‚ö†Ô∏è</td>
                        </tr>
                        <tr>
                            <td class="py-3 px-2 text-pink-400 font-bold">Diffusion</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">2020</td>
                            <td class="py-3 px-2 dl-text-secondary">G√©n√©ration d'images</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">~100 √©tapes</td>
                        </tr>
                        <tr class="bg-teal-500/5">
                            <td class="py-3 px-2 text-teal-400 font-bold">Mamba/SSM</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">2023</td>
                            <td class="py-3 px-2 dl-text-secondary">S√©quences longues</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">O(n) ‚úì</td>
                        </tr>
                        <tr class="bg-amber-500/5">
                            <td class="py-3 px-2 text-amber-400 font-bold">RWKV</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">2023</td>
                            <td class="py-3 px-2 dl-text-secondary">RNN scalable</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">O(n) train, O(1) infer</td>
                        </tr>
                        <tr class="bg-orange-500/5">
                            <td class="py-3 px-2 text-orange-400 font-bold">KAN</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">2024</td>
                            <td class="py-3 px-2 dl-text-secondary">Fonctions interpr√©tables</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">Splines sur ar√™tes</td>
                        </tr>
                        <tr class="bg-cyan-500/5">
                            <td class="py-3 px-2 text-cyan-400 font-bold">LFM (Liquid)</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">2024</td>
                            <td class="py-3 px-2 dl-text-secondary">Edge AI, temps r√©el</td>
                            <td class="py-3 px-2 dl-text-muted text-xs">10x moins de params</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="dl-card bg-gradient-to-r from-blue-500/10 to-purple-500/10 border-l-4 border-purple-500 p-6">
                <p class="text-sm dl-text-secondary">
                    <strong class="text-purple-400">Note :</strong> Ces architectures peuvent se combiner ! Les mod√®les multimodaux modernes (GPT-4 Vision, Gemini) fusionnent Transformers et techniques de vision. Les mod√®les de diffusion utilisent souvent des U-Net (variante de CNN) avec de l'attention (Transformers). L'avenir est probablement aux <strong>hybrides</strong>.
                </p>
            </div>
        </section>

    </main>

    <footer class="dl-footer border-t py-8 text-center text-sm">
        <p>Deep Learning pour l'impatient ‚Äî Slide 10/13</p>
    </footer>

</body>
</html>
